{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dddd55b8-49f9-4ef6-b463-36c5946a06f5",
   "metadata": {},
   "source": [
    "## README:\n",
    "This file contains a class called `cleanData` that is responsible for running the basic cleanings for the course datasets.\\\n",
    "Inside cleanData, functions can perform the following tasks:\n",
    "- asserts whether current file is a csv\n",
    "- reads the csv file\n",
    "- extracts the list of quantitative questions from the question dictionary\n",
    "- transforms numerical values that are identified as strings into numbers\n",
    "- joins necessary columns needed for the faculty dashboard together, columns include:\n",
    "    - `Email`\n",
    "    - `TeamNumber`\n",
    "    - `TeammateNumber`\n",
    "    - `RecipientLastName`\n",
    "    - `RecipientFirstName`\n",
    "    - `RecipientEmail` (repeating `Email` column; will remove later)\n",
    "- maps the agree/disagree scale to number scale\n",
    "    - survey answer format will change (?) so consider removing this function later\n",
    "- normalize the data on scale for visualization purpose\n",
    "- sorts the numerical columns in the dataset\\\n",
    "$\\vdots$\\\n",
    "more coming soon\n",
    "  \n",
    "For each individual courses, its dataset will first be passed into `cleanData.main()` for basic cleaning.\\\n",
    "If specific aspects/questions requested, then create a separate class to address in detail to maintain abstraction.\n",
    "\n",
    "E.g. for ME292C, we are asked to rank team performance:\n",
    "- performance across all questions\n",
    "- performance split by question category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e58f24cc-5d29-493e-9b4c-f7dfced7b341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66d8d260-6026-4706-8d52-80814d92b1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', None)\n",
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9169724f-dae0-4e19-b372-0499e226b401",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cleanData:\n",
    "    def __init__(self, raw_data, question_dictionary, roster):\n",
    "        self.raw_data = raw_data\n",
    "        self.question_dict = question_dictionary\n",
    "        self.roster = roster\n",
    "        \n",
    "        self.subset_data = raw_data\n",
    "        self.needsNormalization = True\n",
    "        self.needsMapping = True\n",
    "    \n",
    "    # assert all files are of .csv extension \n",
    "    def assertCSVFiles(self):\n",
    "        if not \"CSV\" in self.raw_data.upper():\n",
    "            raise Exception(\"raw data file is not in CSV format\")\n",
    "        if not \"CSV\" in self.roster.upper():\n",
    "            raise Exception(\"roster file is not in CSV format\")\n",
    "        if not \"CSV\" in self.question_dict.upper():\n",
    "            raise Exception(\"question dictionary file is not in CSV format\")\n",
    "        \n",
    "        # if still want to check all files together\n",
    "        # if not any([\"CSV\" in [self.raw_data.upper(), self.roster.upper(), self.question_dict.upper()]]):\n",
    "        #     raise Exception(\"At least one of the input files is not in CSV format\")\n",
    "\n",
    "    # read all CSV files \n",
    "    def readCSVs(self):\n",
    "        self.raw_data = pd.read_csv(self.raw_data)\n",
    "        self.question_dict = pd.read_csv(self.question_dict)\n",
    "        self.roster = pd.read_csv(self.roster)\n",
    "\n",
    "    # return the list of quantitative questions from question_dictionary\n",
    "    def getQuantQuestions(self):\n",
    "        quant_dict = self.question_dict[self.question_dict[\"type\"] == \"quantitative\"]\n",
    "        return list(quant_dict[\"question_id\"])\n",
    "\n",
    "    # subset raw data to just student email, student first name, student last name, and all question responses \n",
    "    def getSubset(self):\n",
    "        cols_needed = []\n",
    "        keywords_list = ['EMAIL', 'FIRST', 'LAST', 'Q']\n",
    "        for col in list(self.raw_data.columns):\n",
    "            if any(keyword in col.upper() for keyword in keywords_list):\n",
    "                cols_needed.append(col)\n",
    "\n",
    "        # update class variable subset_data to the correct subset\n",
    "        self.subset_data = self.raw_data[cols_needed]\n",
    "\n",
    "        # replace question column names in subset data with X.Y instead of QX_Y\n",
    "        self.subset_data.columns = [col.replace('Q', '').replace('_', '.') for col in list(self.subset_data.columns)]\n",
    "        return self.subset_data\n",
    "\n",
    "    # join in TeamNumber and TeammateNumber from roster; drop rows of metadata\n",
    "    def joinRosterAndRaw(self):\n",
    "        roster_email_field = [col for col in list(self.roster.columns) if 'EMAIL' in col.upper()][0]\n",
    "        cleaned_email_field = [col for col in list(self.getSubset().columns) if 'EMAIL' in col.upper()][0]\n",
    "\n",
    "        # joins roster (Email) and raw (RecipientEmail)'s subset data on same email address\n",
    "        full_cleaned = pd.merge(self.roster[[roster_email_field, 'TeamNumber', 'TeammateNumber']], \n",
    "                                self.subset_data, \n",
    "                                how=\"outer\", \n",
    "                                left_on = roster_email_field, \n",
    "                                right_on = cleaned_email_field)\n",
    "        \n",
    "        # drop N/A rows, and sort df by TeamNumber then TeammateNumber starting from Team1\n",
    "        full_cleaned = full_cleaned[~full_cleaned[\"TeamNumber\"].isna()]\n",
    "        full_cleaned = full_cleaned.sort_values([\"TeamNumber\", \"TeammateNumber\"]).reset_index().drop(\"index\", axis=1)\n",
    "\n",
    "        # removes redundancy of the 2 emails columns \n",
    "        full_cleaned = full_cleaned.drop('RecipientEmail', axis=1)\n",
    "        return full_cleaned\n",
    "        \n",
    "    # fix numbers in quantitative questions that are identified as strings into integers\n",
    "    def stringToNumerical(self, data):\n",
    "        for question in self.getQuantQuestions():\n",
    "            question_str = str(question)\n",
    "            lst = data[question_str].str.contains(r'\\d+')\n",
    "            filtered_lst = [x for x in lst if not (x is np.nan)]\n",
    "            if any(filtered_lst):\n",
    "                data[question_str] = pd.to_numeric(data[question_str])   \n",
    "        return data\n",
    "\n",
    "    def sortColumns(self, data):\n",
    "        # transform data columns into float for sorting purpose\n",
    "        for column in data.columns[5:]:  # 6 can change based on joinRosterAndRaw()\n",
    "            data.rename(columns={column: float(column)}, inplace=True)\n",
    "\n",
    "        sorted = data.iloc[:, 5:]\n",
    "        sorted = sorted.sort_index(axis=1)\n",
    "        sorted['Email'] = data['Email']\n",
    "        data = data.iloc[:, :5]    \n",
    "        \n",
    "        return pd.merge(data, sorted, on='Email')\n",
    "        \n",
    "    def mappingScale(self, maxScale):\n",
    "        seven_scale_mappings = {\n",
    "        \"STRONGLY AGREE\" : 7,\n",
    "        \"AGREE\" : 6,\n",
    "        \"SOMEWHAT AGREE\" : 5,\n",
    "        \"NEITHER AGREE NOR DISAGREE\" : 4,\n",
    "        \"SOMEWHAT DISAGREE\" : 3,\n",
    "        \"DISAGREE\" : 2,\n",
    "        \"STRONGLY DISAGREE\" : 1,\n",
    "        np.nan : np.nan,\n",
    "        \"MUCH BETTER\" : 7,\n",
    "        \"MODERATELY BETTER\" : 6,\n",
    "        \"SLIGHTLY BETTER\" : 5,\n",
    "        \"ABOUT THE SAME\" : 4,\n",
    "        \"SLIGHTLY WORSE\" : 3,\n",
    "        \"MODERATELY WORSE\" : 2,\n",
    "        \"MUCH WORSE\" : 1,\n",
    "        }\n",
    "\n",
    "        five_scale_mappings = {\n",
    "            \"ALWAYS\" : 5,\n",
    "            \"VERY OFTEN\" : 4,\n",
    "            \"SOMETIMES\" : 3,\n",
    "            \"RARELY\" : 2,\n",
    "            \"NEVER\" : 1,\n",
    "            np.nan : np.nan\n",
    "        }\n",
    "        if maxScale == 7:\n",
    "            return seven_scale_mappings\n",
    "        return five_scale_mappings\n",
    "\n",
    "    # if the raw data has \"Agree\"/\"Disagree\" in quantitative question columns, map these to integers 1-X where X is \"out_of\"\n",
    "    def mapData(self, data):\n",
    "        for question in self.getQuantQuestions():\n",
    "            # get the max scale of current question\n",
    "            maxScale = int(self.question_dict[self.question_dict[\"question_id\"] == question][\"out_of\"])\n",
    "            scaleFunction = self.mappingScale(maxScale)\n",
    "            question_str = str(question)\n",
    "            \n",
    "            if maxScale == 7 or maxScale == 5:\n",
    "                data[question_str] = data[question_str].str.upper()\n",
    "    \n",
    "                # starts mapping relevant questions\n",
    "                lstOfResponses = []\n",
    "                for response in data[question_str]:\n",
    "                    lstOfResponses.append(scaleFunction[response])\n",
    "                data[question_str] = lstOfResponses\n",
    "        return data\n",
    "        \n",
    "    # if normalization is true, then all quantitative data is normed to 0\n",
    "    # assumed question_dictionary includes \"out_of\" column\n",
    "    def normalize(self, data):\n",
    "        for question in self.getQuantQuestions():\n",
    "            # get the max scale of current question\n",
    "            maxScale = int(self.question_dict[self.question_dict[\"question_id\"] == question][\"out_of\"])\n",
    "            scaleFunction = self.mappingScale(maxScale)\n",
    "            question_str = str(question)\n",
    "            \n",
    "            # if series values are agree/disagree, adjust the scale for visualization purpose\n",
    "            if maxScale == 7:\n",
    "                data[question_str] = pd.to_numeric(data[question_str]) - 4\n",
    "            else:\n",
    "                data[question_str] = pd.to_numeric(data[question_str]) - 3\n",
    "        return data\n",
    "\n",
    "    # For NA values (students that didn't complete survey, left question empty), fill quantitative questions with 0\n",
    "    def fillQuantNA(self, data):\n",
    "        data = data.fillna(0)\n",
    "        return data\n",
    "\n",
    "    def main(self):\n",
    "        self.assertCSVFiles()\n",
    "        # reads CSVs\n",
    "        self.readCSVs()\n",
    "\n",
    "        # joins subset of roster and raw data\n",
    "        data = self.joinRosterAndRaw()\n",
    "        data = self.stringToNumerical(data)\n",
    "        \n",
    "        if self.needsMapping:\n",
    "            data = self.mapData(data)\n",
    "\n",
    "        if self.needsNormalization:\n",
    "            data = self.normalize(data)\n",
    "        data = self.sortColumns(data)\n",
    "        data = self.fillQuantNA(data)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3de3cb69-6c08-4c63-aa12-e4a6a103be54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/doladou/Desktop/pipeline/data/cleaning'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "# this can vary for different computers\n",
    "# replace the following string after %run to run this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aeff94-f1d3-4f30-9331-2db0321dacce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
